apiVersion: actions.github.com/v1alpha1
kind: AutoscalingRunnerSet
metadata:
  name: nprd-autoscale-runners
  namespace: managed-cicd
  labels:
    # Version label (as per official documentation)
    # Documentation mentions app.kubernetes.io/version=<chart version> for pods
    # Trying same format for AutoscalingRunnerSet
    # Downgraded to 0.12.1 to avoid JIT config double-encoding bug in 0.13.0/0.13.1
    app.kubernetes.io/version: "0.12.1"
  annotations:
    # NOTE: Official troubleshooting docs don't mention version annotations
    # Version may be managed via Helm chart, not manual annotations
    # Keeping minimal annotations for now
spec:
  # Organization-level runner scale set
  # Available to all repositories in the organization
  # Runners are assigned to a runner group for access control
  githubConfigUrl: https://github.com/DataKnifeAI
  
  # Authentication secret (REQUIRED)
  # Secret created by Terraform with GitHub App credentials
  githubConfigSecret: github-app-secret
  
  # Runner group name (must exist in GitHub org settings)
  # Create this group in: https://github.com/organizations/DataKnifeAI/settings/actions/runners
  # Configure it to allow "All repositories" or select specific repos
  # IMPORTANT: For PUBLIC repositories, you MUST enable "Allow public repositories" flag
  # in the runner group settings, otherwise workflows will remain queued!
  # Go to: https://github.com/organizations/DataKnifeAI/settings/actions/runner-groups
  # Click on your group → Enable "Allow public repositories" → Save
  # NOTE: Runner group must exist BEFORE creating this resource
  runnerGroup: NRPD Auto Scale
  
  # Runner scale set name (used in GitHub)
  # IMPORTANT: ARC runner scale sets expose ONLY this name as a label
  # Per official docs: https://docs.github.com/en/actions/tutorials/use-actions-runner-controller/use-arc-in-a-workflow
  # "You cannot use additional labels to target runners created by ARC.
  # You can only use the installation name...or runnerScaleSetName field.
  # These are used as the 'single label' to use as your runs-on target."
  # Workflows must use: runs-on: <runnerScaleSetName>
  #
  # CRITICAL: Known bug with "self-hosted" label (GitHub issue #3330)
  # ARC runners may not automatically receive "self-hosted" label
  # Using "kubernetes" instead to avoid this known issue
  # Workflow updated to use: runs-on: kubernetes
  runnerScaleSetName: kubernetes
  
  # Maximum number of runners that can be created
  maxRunners: 0
  
  # Minimum number of runners to maintain
  # Set to 0 for true ephemeral behavior - runners are created on-demand and cleaned up after jobs
  minRunners: 0
  
  # Container spec for the runner pods
  template:
    spec:
      # CRITICAL FIX: Set restartPolicy to Never for ephemeral runners
      # With Always (default), Kubernetes restarts completed pods, causing endless loop
      # Ephemeral runners should exit cleanly and NOT restart
      # This is the KEY missing configuration causing the endless loop!
      restartPolicy: Never
      
      containers:
      - name: runner
        image: ghcr.io/actions/actions-runner:latest
        resources:
          # Increased requests to prevent premature exits
          # Low resource requests can cause pods to exit prematurely
          requests:
            cpu: 500m  # Increased from 100m to prevent resource starvation
            memory: 512Mi  # Increased from 128Mi to prevent OOM kills
          limits:
            cpu: "2"  # Use normalized format to match Kubernetes (2000m = 2)
            memory: 4Gi
  
  # Official ARC uses ephemeral runners by default
  # Ephemeral runners automatically clean up after job completion
  # This is built-in behavior - there's no ephemeral field to configure
  # With minRunners: 0 and maxRunners: 0, runners are created on-demand and scale to zero when idle
